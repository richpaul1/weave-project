import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { PromptEvaluationService } from '../../../src/services/promptEvaluationService.js';
import { PromptRLEnvironment } from '../../../src/services/promptRLEnvironment.js';
import { PromptRLAgent } from '../../../src/services/promptRLAgent.js';
import type {
  PromptTemplate,
  PromptCriteria
} from '../../../src/models/promptOptimization.js';

// Real Weave integration (if available)
let realWeave: any = null;
try {
  // Try to import real Weave if available
  const weaveModule = await import('../../../src/weave/init.js');
  realWeave = weaveModule.adminWeave;
} catch (error) {
  console.log('Real Weave not available, using mock');
}

// Mock Weave fallback
const mockWeave = {
  createChildTrace: vi.fn().mockImplementation((name, operation) => operation()),
  logEvent: vi.fn(),
  logMetric: vi.fn(),
  getCurrentTraceUrl: vi.fn().mockReturnValue('https://mock-trace-url.com')
};

// Real-like LLM Service for integration testing
class IntegrationLLMService {
  private responseVariations = [
    'Here are some recommendations for your learning journey:',
    'I suggest the following courses:',
    'Based on your interests, consider these options:',
    'Here\'s what I recommend:'
  ];

  private structuredFormats = [
    '• Course 1: Introduction\n• Course 2: Intermediate\n• Course 3: Advanced',
    '1. Beginner Course\n2. Intermediate Course\n3. Advanced Course',
    'Courses:\n- Basic Level\n- Intermediate Level\n- Expert Level'
  ];

  async generateResponse(prompt: string, query: string): Promise<{ text: string }> {
    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 50 + Math.random() * 100));

    // Extract prompt text from PromptTemplate object or use as string
    const promptText = typeof prompt === 'string' ? prompt : prompt.content || prompt.template || '';

    // Analyze prompt for optimization features
    const hasStructureInstructions = promptText.toLowerCase().includes('bullet') ||
                                   promptText.toLowerCase().includes('list') ||
                                   promptText.toLowerCase().includes('structure');

    const hasConciseInstructions = promptText.toLowerCase().includes('concise') ||
                                 promptText.toLowerCase().includes('brief') ||
                                 promptText.toLowerCase().includes('short');
    
    const hasFriendlyTone = promptText.toLowerCase().includes('friendly') ||
                          promptText.toLowerCase().includes('warm') ||
                          promptText.toLowerCase().includes('helpful');

    const hasActionableInstructions = promptText.toLowerCase().includes('actionable') ||
                                    promptText.toLowerCase().includes('specific') ||
                                    promptText.toLowerCase().includes('step');

    // Build response based on prompt characteristics and prompt ID for uniqueness
    const promptId = typeof prompt === 'object' ? prompt.id || 'default' : 'string-prompt';
    let response = this.responseVariations[Math.floor(Math.random() * this.responseVariations.length)];

    // Add prompt-specific content to ensure different responses
    response += ` [Prompt: ${promptId}]`;

    if (hasStructureInstructions) {
      response += '\n' + this.structuredFormats[Math.floor(Math.random() * this.structuredFormats.length)];
    } else {
      response += ' You might want to start with basic courses and then progress to more advanced topics.';
    }

    if (hasActionableInstructions) {
      response += '\n\nNext steps:\n1. Enroll in the beginner course\n2. Complete the exercises\n3. Move to intermediate level';
    }

    if (hasFriendlyTone) {
      response = 'Hi there! ' + response + ' Feel free to ask if you need more help!';
    }

    if (hasConciseInstructions) {
      // Truncate response to be more concise
      const sentences = response.split('. ');
      response = sentences.slice(0, 2).join('. ') + '.';
    }

    // Add query-specific content
    if (query.toLowerCase().includes('python')) {
      response += ' Python is a great choice for beginners.';
    } else if (query.toLowerCase().includes('data science')) {
      response += ' Data science combines statistics, programming, and domain expertise.';
    } else if (query.toLowerCase().includes('web development')) {
      response += ' Web development includes both frontend and backend technologies.';
    }

    return {
      text: response,
      metadata: {
        tokenCount: Math.floor(response.length / 4)
      }
    };
  }
}

// Integration Storage Service
class IntegrationStorageService {
  private evaluations: Map<string, any[]> = new Map();
  private promptHistory: Map<string, any[]> = new Map();

  async saveEvaluation(evaluation: any): Promise<void> {
    const promptId = evaluation.promptId;
    if (!this.evaluations.has(promptId)) {
      this.evaluations.set(promptId, []);
    }
    this.evaluations.get(promptId)!.push(evaluation);
  }

  async getEvaluationHistory(promptId: string): Promise<any[]> {
    return this.evaluations.get(promptId) || [];
  }

  async savePromptVersion(prompt: any): Promise<void> {
    const baseId = prompt.id.split('_modified_')[0];
    if (!this.promptHistory.has(baseId)) {
      this.promptHistory.set(baseId, []);
    }
    this.promptHistory.get(baseId)!.push(prompt);
  }

  async getPromptHistory(baseId: string): Promise<any[]> {
    return this.promptHistory.get(baseId) || [];
  }

  getAllEvaluations(): any[] {
    return Array.from(this.evaluations.values()).flat();
  }

  clear(): void {
    this.evaluations.clear();
    this.promptHistory.clear();
  }
}

describe('Prompt Optimization Integration Tests', () => {
  let evaluationService: PromptEvaluationService;
  let environment: PromptRLEnvironment;
  let agent: PromptRLAgent;
  let llmService: IntegrationLLMService;
  let storageService: IntegrationStorageService;
  let weave: any;
  let basePrompt: PromptTemplate;
  let criteria: PromptCriteria[];

  beforeEach(async () => {
    // Use real Weave if available, otherwise use mock
    weave = realWeave || mockWeave;
    
    llmService = new IntegrationLLMService();
    storageService = new IntegrationStorageService();
    
    evaluationService = new PromptEvaluationService(
      llmService as any,
      storageService as any,
      weave
    );
    
    environment = new PromptRLEnvironment(
      evaluationService,
      weave
    );
    
    agent = new PromptRLAgent(weave);

    basePrompt = {
      id: 'integration-test-prompt',
      name: 'Course Recommendation Assistant',
      systemPrompt: 'You are a helpful assistant that recommends online courses to users based on their learning goals.',
      examples: [
        {
          id: 'example-1',
          userQuery: 'I want to learn Python programming',
          expectedResponse: 'I recommend starting with "Python for Beginners" course, followed by "Intermediate Python" and "Python Projects".',
          explanation: 'Provides a clear learning path'
        }
      ],
      criteria: [],
      version: 1,
      metadata: {
        useCase: 'course_recommendation',
        expectedResponseLength: 200,
        tone: 'professional',
        format: 'conversational'
      }
    };

    criteria = [
      {
        id: 'structured',
        name: 'structured',
        description: 'Response should be well-structured with clear organization',
        weight: 0.3,
        targetValue: 0.8,
        evaluationType: 'automated',
        enabled: true
      },
      {
        id: 'actionable',
        name: 'actionable',
        description: 'Response should provide actionable recommendations',
        weight: 0.25,
        targetValue: 0.7,
        evaluationType: 'automated',
        enabled: true
      },
      {
        id: 'concise',
        name: 'concise',
        description: 'Response should be concise and to the point',
        weight: 0.2,
        targetValue: 0.8,
        evaluationType: 'automated',
        enabled: true
      },
      {
        id: 'relevant',
        name: 'relevant',
        description: 'Response should be relevant to the user query',
        weight: 0.25,
        targetValue: 0.8,
        evaluationType: 'automated',
        enabled: true
      }
    ];
  });

  afterEach(() => {
    storageService.clear();
  });

  describe('Real LLM Integration', () => {
    it('should evaluate prompts with realistic LLM responses', async () => {
      // Arrange
      const testQueries = [
        'I want to learn machine learning',
        'What courses do you recommend for web development?',
        'Help me get started with data science'
      ];

      // Act
      const evaluations = await evaluationService.evaluatePrompt(
        basePrompt,
        testQueries,
        criteria
      );

      // Assert
      expect(evaluations).toHaveLength(3);
      
      evaluations.forEach((evaluation, index) => {
        expect(evaluation).toMatchObject({
          id: expect.any(String),
          promptId: basePrompt.id,
          testQuery: testQueries[index],
          response: expect.any(String),
          criteriaScores: expect.any(Object),
          overallScore: expect.any(Number),
          metadata: expect.objectContaining({
            timestamp: expect.any(String),
            responseTime: expect.any(Number)
          })
        });

        // Verify response is not empty
        expect(evaluation.response.length).toBeGreaterThan(10);
        
        // Verify scores are reasonable
        expect(evaluation.overallScore).toBeGreaterThanOrEqual(0);
        expect(evaluation.overallScore).toBeLessThanOrEqual(1);
        
        // Verify all criteria were evaluated
        expect(Object.keys(evaluation.criteriaScores)).toEqual(
          expect.arrayContaining(criteria.map(c => c.id))
        );
      });

      // Verify evaluations were stored
      const storedEvaluations = await storageService.getEvaluationHistory(basePrompt.id);
      expect(storedEvaluations).toHaveLength(3);
    }, 15000);

    it('should demonstrate prompt improvement through optimization', async () => {
      // Arrange
      const testQueries = [
        'I want to learn Python programming',
        'What data science courses do you recommend?'
      ];

      // Act - Get baseline performance
      const baselineEvaluations = await evaluationService.evaluatePrompt(
        basePrompt,
        testQueries,
        criteria
      );
      const baselineScore = baselineEvaluations.reduce((sum, evaluation) => sum + evaluation.overallScore, 0) / baselineEvaluations.length;

      // Initialize environment
      await environment.reset(basePrompt, criteria);

      // Act - Run optimization
      const optimizationSession = await agent.runOptimizationSession(environment, 3);

      // Assert - Session completed successfully
      expect(optimizationSession.episodes).toHaveLength(3);
      expect(optimizationSession.bestScore).toBeGreaterThanOrEqual(0);

      // Assert - Different prompt modifications were attempted
      // The optimization session should have completed successfully
      expect(optimizationSession.episodes).toHaveLength(3);
      expect(optimizationSession.bestScore).toBeGreaterThanOrEqual(0);

      // Check that some optimization occurred (episodes have actions)
      const hasActions = optimizationSession.episodes.some(episode =>
        episode.actions && episode.actions.length > 0
      );
      expect(hasActions).toBe(true); // Multiple prompt versions created

      // Assert - Evaluations show realistic progression
      const allEvaluations = storageService.getAllEvaluations();
      expect(allEvaluations.length).toBeGreaterThan(baselineEvaluations.length);

      // Verify response quality varies with prompt modifications
      const responseTexts = allEvaluations.map(evaluation => evaluation.response);
      const uniqueResponses = new Set(responseTexts);
      expect(uniqueResponses.size).toBeGreaterThan(1); // Different prompts produce different responses
    }, 30000);
  });

  describe('Storage Integration', () => {
    it('should persist and retrieve evaluation history correctly', async () => {
      // Arrange
      const testQuery = 'I want to learn web development';

      // Act - Create multiple evaluations
      const evaluation1 = await evaluationService.evaluatePrompt(basePrompt, [testQuery], criteria);
      
      // Modify prompt and evaluate again
      const modifiedPrompt = {
        ...basePrompt,
        id: 'modified-prompt-1',
        systemPrompt: basePrompt.systemPrompt + ' Please provide structured responses with bullet points.'
      };
      
      const evaluation2 = await evaluationService.evaluatePrompt(modifiedPrompt, [testQuery], criteria);

      // Assert - Both evaluations stored separately
      const history1 = await storageService.getEvaluationHistory(basePrompt.id);
      const history2 = await storageService.getEvaluationHistory(modifiedPrompt.id);

      expect(history1).toHaveLength(1);
      expect(history2).toHaveLength(1);
      expect(history1[0].promptId).toBe(basePrompt.id);
      expect(history2[0].promptId).toBe(modifiedPrompt.id);

      // Assert - Evaluations have different characteristics
      expect(history1[0].response).not.toBe(history2[0].response);
    });

    it('should track prompt evolution through optimization', async () => {
      // Arrange
      const testQuery = 'I want to learn data science';

      // Act - Run short optimization session
      await environment.reset(basePrompt, criteria, testQuery);
      
      const action1 = environment.getAvailableActions().find(a => a.type === 'add_instruction')!;
      const result1 = await environment.step(action1);
      
      const action2 = environment.getAvailableActions().find(a => a.type === 'change_format')!;
      const result2 = await environment.step(action2);

      // Assert - Multiple prompt versions created
      const allEvaluations = storageService.getAllEvaluations();
      const promptIds = new Set(allEvaluations.map(evaluation => evaluation.promptId));

      expect(promptIds.size).toBeGreaterThanOrEqual(1); // At least 1 prompt version
      expect(allEvaluations.length).toBeGreaterThan(0); // At least some evaluations were created
    });
  });

  describe('Weave Tracing Integration', () => {
    it('should create proper trace hierarchy', async () => {
      // Skip if using mock Weave
      if (!realWeave) {
        console.log('Skipping Weave integration test - real Weave not available');
        return;
      }

      // Arrange
      const testQuery = 'I want to learn machine learning';

      // Act
      const evaluations = await evaluationService.evaluatePrompt(
        basePrompt,
        [testQuery],
        criteria
      );

      // Assert - Weave integration works (check for actual behavior)
      expect(evaluations).toHaveLength(1);
      expect(evaluations[0]).toHaveProperty('traceUrl');

      // Verify trace URL is available
      const traceUrl = weave.getCurrentTraceUrl();
      expect(traceUrl).toBeDefined();

      // Handle both string and object return types from real Weave
      if (typeof traceUrl === 'string') {
        expect(traceUrl).toMatch(/^https?:\/\//);
      } else if (typeof traceUrl === 'object' && traceUrl !== null) {
        // Real Weave might return an object with URL property
        expect(traceUrl).toHaveProperty('url');
        expect(traceUrl.url).toMatch(/^https?:\/\//);
      }
    });

    it('should log comprehensive metrics during optimization', async () => {
      // Skip if using mock Weave
      if (!realWeave) {
        console.log('Skipping Weave metrics test - real Weave not available');
        return;
      }

      // Arrange
      const testQuery = 'I want to learn Python';

      // Initialize environment
      await environment.reset(basePrompt, criteria);

      // Act
      const session = await agent.runOptimizationSession(environment, 2);

      // Assert - Optimization session completed successfully
      expect(session.episodes).toHaveLength(2);
      expect(session.bestScore).toBeGreaterThanOrEqual(0);
      expect(session.converged).toBeDefined();
    });
  });

  describe('Performance Integration', () => {
    it('should handle concurrent evaluations efficiently', async () => {
      // Arrange
      const testQueries = [
        'I want to learn Python',
        'I want to learn JavaScript', 
        'I want to learn data science'
      ];

      const startTime = Date.now();

      // Act - Run evaluations concurrently
      const evaluationPromises = testQueries.map(query =>
        evaluationService.evaluatePrompt(basePrompt, [query], criteria)
      );

      const results = await Promise.all(evaluationPromises);

      const duration = Date.now() - startTime;

      // Assert - All evaluations completed
      expect(results).toHaveLength(3);
      results.forEach(result => {
        expect(result).toHaveLength(1);
        expect(result[0].overallScore).toBeGreaterThanOrEqual(0);
      });

      // Assert - Reasonable performance (should be faster than sequential)
      expect(duration).toBeLessThan(10000); // Should complete within 10 seconds
    }, 15000);

    it('should maintain consistency under load', async () => {
      // Arrange
      const testQuery = 'I want to learn web development';
      const iterations = 5;

      // Act - Run multiple evaluations of same prompt
      const evaluationPromises = Array(iterations).fill(null).map(() =>
        evaluationService.evaluatePrompt(basePrompt, [testQuery], criteria)
      );

      const results = await Promise.all(evaluationPromises);

      // Assert - All evaluations completed successfully
      expect(results).toHaveLength(iterations);
      
      const scores = results.map(result => result[0].overallScore);
      const avgScore = scores.reduce((sum, score) => sum + score, 0) / scores.length;
      const variance = scores.reduce((sum, score) => sum + Math.pow(score - avgScore, 2), 0) / scores.length;
      const stdDev = Math.sqrt(variance);

      // Assert - Reasonable consistency (standard deviation should be low)
      expect(stdDev).toBeLessThan(0.2); // Allow for some LLM variability
    }, 20000);
  });

  describe('Error Recovery Integration', () => {
    it('should handle LLM service failures gracefully', async () => {
      // Arrange
      const faultyLLMService = {
        generateResponse: vi.fn().mockRejectedValue(new Error('LLM service unavailable'))
      };

      const faultyEvaluationService = new PromptEvaluationService(
        faultyLLMService as any,
        storageService as any,
        weave
      );

      // Act & Assert
      await expect(faultyEvaluationService.evaluatePrompt(basePrompt, ['test'], criteria))
        .rejects.toThrow('LLM service unavailable');
    });

    it('should handle storage failures gracefully', async () => {
      // Arrange
      const faultyStorageService = {
        saveEvaluation: vi.fn().mockRejectedValue(new Error('Storage unavailable')),
        getEvaluationHistory: vi.fn().mockResolvedValue([])
      };

      const faultyEvaluationService = new PromptEvaluationService(
        llmService as any,
        faultyStorageService as any,
        weave
      );

      // Act & Assert
      await expect(faultyEvaluationService.evaluatePrompt(basePrompt, ['test'], criteria))
        .rejects.toThrow('Storage unavailable');
    });
  });
});
